{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sudoku Solver using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sudoku puzzle images\n",
    "puzzle1 = cv2.imread('Puzzles/puzzle1.png')\n",
    "puzzle2 = cv2.imread('Puzzles/puzzle2.png')\n",
    "\n",
    "# Display the images\n",
    "cv2.imshow('Puzzle 1', puzzle1)\n",
    "cv2.imshow('Puzzle 2', puzzle2)\n",
    "cv2.waitKey(5)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (7, 7), 3)\n",
    "    \n",
    "    # Apply adaptive thresholding to get binary image\n",
    "    # Changed THRESH_BINARY_INV to THRESH_BINARY to invert the colors\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                 cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "def find_puzzle(image):\n",
    "    # Preprocess the image\n",
    "    processed = preprocess_image(image)\n",
    "    \n",
    "    # Find contours - invert image temporarily for contour detection\n",
    "    processed_inv = cv2.bitwise_not(processed)\n",
    "    contours, _ = cv2.findContours(processed_inv.copy(), cv2.RETR_EXTERNAL,\n",
    "                                  cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours by area in descending order\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    puzzle_contour = None\n",
    "    \n",
    "    # Loop through contours to find the puzzle grid\n",
    "    for contour in contours:\n",
    "        # Approximate the contour\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        \n",
    "        # If we have found a rectangle with 4 corners, we've found our puzzle\n",
    "        if len(approx) == 4:\n",
    "            puzzle_contour = approx\n",
    "            break\n",
    "            \n",
    "    return puzzle_contour\n",
    "\n",
    "# Process both puzzles\n",
    "puzzle1_processed = preprocess_image(puzzle1)\n",
    "puzzle2_processed = preprocess_image(puzzle2)\n",
    "\n",
    "# Find puzzle contours\n",
    "puzzle1_contour = find_puzzle(puzzle1)\n",
    "puzzle2_contour = find_puzzle(puzzle2)\n",
    "\n",
    "# Draw the contours on the original images\n",
    "if puzzle1_contour is not None:\n",
    "    cv2.drawContours(puzzle1, [puzzle1_contour], -1, (0, 255, 0), 2)\n",
    "if puzzle2_contour is not None:\n",
    "    cv2.drawContours(puzzle2, [puzzle2_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Processed Puzzle 1', puzzle1_processed)\n",
    "cv2.imshow('Processed Puzzle 2', puzzle2_processed)\n",
    "cv2.imshow('Detected Grid 1', puzzle1)\n",
    "cv2.imshow('Detected Grid 2', puzzle2)\n",
    "cv2.waitKey(5)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download digit templates -> Warning: I do not recommend this method. Use the images in the folder instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Saved digit 5 as digit_5.png\n",
      "Saved digit 4 as digit_4.png\n",
      "Saved digit 1 as digit_1.png\n",
      "Saved digit 9 as digit_9.png\n",
      "Saved digit 2 as digit_2.png\n",
      "Saved digit 3 as digit_3.png\n",
      "Saved digit 6 as digit_6.png\n",
      "Saved digit 7 as digit_7.png\n",
      "Saved digit 8 as digit_8.png\n",
      "All specified digit images have been saved.\n"
     ]
    }
   ],
   "source": [
    "assert False, \"I do not recommend this method. Use the images in the folder instead.\"\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from PIL import Image\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (_, _) = mnist.load_data()\n",
    "\n",
    "# Specify the output directory\n",
    "output_dir = 'mnist_digits'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the digits to save\n",
    "digits_to_save = range(1, 10)\n",
    "\n",
    "# Initialize a dictionary to track saved digits\n",
    "saved_digits = {digit: False for digit in digits_to_save}\n",
    "\n",
    "# Iterate over the dataset to find and save one image per digit\n",
    "for image, label in zip(train_images, train_labels):\n",
    "    if label in digits_to_save and not saved_digits[label]:\n",
    "        # Convert the image to a PIL Image object\n",
    "        pil_image = Image.fromarray(image)\n",
    "        # Save the image as a PNG file\n",
    "        pil_image.save(os.path.join(output_dir, f'digit_{label}.png'))\n",
    "        # Mark this digit as saved\n",
    "        saved_digits[label] = True\n",
    "        print(f'Saved digit {label} as digit_{label}.png')\n",
    "    # Break the loop if all digits have been saved\n",
    "    if all(saved_digits.values()):\n",
    "        break\n",
    "\n",
    "print('All specified digit images have been saved.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MNIST model for digit recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1690/1690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.4203 - val_accuracy: 0.9844 - val_loss: 0.0485\n",
      "Epoch 2/5\n",
      "\u001b[1m1690/1690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0780 - val_accuracy: 0.9904 - val_loss: 0.0299\n",
      "Epoch 3/5\n",
      "\u001b[1m1690/1690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0550 - val_accuracy: 0.9906 - val_loss: 0.0272\n",
      "Epoch 4/5\n",
      "\u001b[1m1690/1690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0412 - val_accuracy: 0.9907 - val_loss: 0.0268\n",
      "Epoch 5/5\n",
      "\u001b[1m1690/1690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0342 - val_accuracy: 0.9931 - val_loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Load and preprocess MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape and normalize the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Filter out zeros and convert labels to 0-8 (for digits 1-9)\n",
    "train_mask = (y_train > 0) & (y_train <= 9)\n",
    "test_mask = (y_test > 0) & (y_test <= 9)\n",
    "\n",
    "x_train, y_train = x_train[train_mask], y_train[train_mask] - 1\n",
    "x_test, y_test = x_test[test_mask], y_test[test_mask] - 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),  # Explicit input layer\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(9, activation='softmax')  # 9 outputs for digits 1-9\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                   epochs=5, \n",
    "                   validation_data=(x_test, y_test),\n",
    "                   batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('digit_model.h5')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4330234\n",
      "0.88909674\n",
      "0.73285955\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.20765854\n",
      "0.99967337\n",
      "0.9999988\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.28831974\n",
      "0.9999589\n",
      "0.88794327\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.549113\n",
      "0.9985129\n",
      "0.28761825\n",
      "0.8786603\n",
      "0.9999999\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.9999982\n",
      "0.9767131\n",
      "0.97592735\n",
      "0.4912032\n",
      "0.22035226\n",
      "0.14286034\n",
      "0.14286034\n",
      "1.0\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.5766772\n",
      "0.14286034\n",
      "0.89610183\n",
      "0.14286034\n",
      "0.96141046\n",
      "0.14286034\n",
      "0.14286034\n",
      "1.0\n",
      "0.7002913\n",
      "0.99573475\n",
      "0.98542017\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.94279605\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.3068825\n",
      "0.22431225\n",
      "0.48631167\n",
      "0.96336734\n",
      "0.99999976\n",
      "0.3971767\n",
      "0.9951444\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.9953798\n",
      "0.62803537\n",
      "0.3141681\n",
      "0.14286034\n",
      "0.8330071\n",
      "0.14286034\n",
      "0.99999845\n",
      "0.14286034\n",
      "0.14286034\n",
      "1.0\n",
      "0.9876324\n",
      "0.32191592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14286034\n",
      "0.555913\n",
      "0.14286034\n",
      "0.5338051\n",
      "0.14286034\n",
      "0.9999989\n",
      "[[9 4 6 0 0 0 8 3 0]\n",
      " [0 0 8 8 0 0 0 4 5]\n",
      " [0 7 3 0 0 2 1 9 8]\n",
      " [0 0 0 2 0 0 0 0 1]\n",
      " [0 9 0 1 0 0 3 3 8]\n",
      " [8 0 0 0 0 0 4 0 0]\n",
      " [8 0 1 3 2 8 9 0 0]\n",
      " [4 6 8 0 1 0 2 0 0]\n",
      " [2 8 8 0 9 0 9 0 3]]\n",
      "0.28831974\n",
      "0.99822456\n",
      "0.9999995\n",
      "0.9984438\n",
      "0.36043528\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.83825415\n",
      "0.99999917\n",
      "0.28831974\n",
      "0.8890118\n",
      "0.6449865\n",
      "0.99954164\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.9775277\n",
      "0.14286034\n",
      "0.28761825\n",
      "0.999203\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.9999796\n",
      "1.0\n",
      "0.14286034\n",
      "0.79506814\n",
      "0.9997471\n",
      "0.14286034\n",
      "0.14286034\n",
      "1.0\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.30255356\n",
      "0.997436\n",
      "0.89877474\n",
      "0.14286034\n",
      "0.97701204\n",
      "0.14286034\n",
      "0.9824891\n",
      "0.836071\n",
      "0.14286034\n",
      "0.32790223\n",
      "0.29968688\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.99802643\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.9989323\n",
      "0.99999976\n",
      "0.32517096\n",
      "0.99999905\n",
      "0.9644885\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.14286034\n",
      "0.944473\n",
      "0.14286034\n",
      "0.32191592\n",
      "0.93429804\n",
      "0.23510462\n",
      "0.20061472\n",
      "0.99961036\n",
      "0.96673566\n",
      "0.9867628\n",
      "0.14286034\n",
      "0.99797624\n",
      "0.6857641\n",
      "0.32191592\n",
      "0.33731887\n",
      "0.33731887\n",
      "0.30546585\n",
      "0.9485369\n",
      "0.99919206\n",
      "0.99053943\n",
      "0.14286034\n",
      "[[0 7 3 1 2 0 0 0 6]\n",
      " [8 0 6 7 2 0 0 1 0]\n",
      " [0 5 0 0 0 0 2 3 0]\n",
      " [4 1 0 0 3 0 0 0 0]\n",
      " [2 9 5 0 6 0 3 9 0]\n",
      " [8 0 0 0 1 0 0 9 3]\n",
      " [8 8 4 0 0 0 0 6 0]\n",
      " [8 6 0 0 8 4 1 0 9]\n",
      " [7 8 8 8 8 6 8 5 0]]\n",
      "Could not solve Puzzle 1\n",
      "Could not solve Puzzle 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def extract_digits(processed_image, contour):\n",
    "    # Get perspective transform\n",
    "    pts = contour.reshape(4, 2)\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    \n",
    "    # Order points: top-left, top-right, bottom-right, bottom-left\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    # Get width and height of the grid\n",
    "    widthA = np.sqrt(((rect[2][0] - rect[3][0]) ** 2) + ((rect[2][1] - rect[3][1]) ** 2))\n",
    "    widthB = np.sqrt(((rect[1][0] - rect[0][0]) ** 2) + ((rect[1][1] - rect[0][1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    \n",
    "    heightA = np.sqrt(((rect[1][0] - rect[2][0]) ** 2) + ((rect[1][1] - rect[2][1]) ** 2))\n",
    "    heightB = np.sqrt(((rect[0][0] - rect[3][0]) ** 2) + ((rect[0][1] - rect[3][1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    \n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "    \n",
    "    # Apply perspective transform\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(processed_image, M, (maxWidth, maxHeight))\n",
    "    \n",
    "    # Load trained digit recognition model\n",
    "    model = tf.keras.models.load_model('digit_model.h5')\n",
    "    \n",
    "    # Create 9x9 grid\n",
    "    cell_height = maxHeight // 9\n",
    "    cell_width = maxWidth // 9\n",
    "    grid = np.zeros((9, 9), dtype=int)\n",
    "    # Extract each cell\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            cell = warped[i*cell_height:(i+1)*cell_height, j*cell_width:(j+1)*cell_width]\n",
    "            \n",
    "            # Add padding to cell\n",
    "            pad = 5\n",
    "            cell = cell[pad:-pad, pad:-pad]\n",
    "                \n",
    "            # Preprocess cell for model\n",
    "            cell = cv2.resize(cell, (28, 28))\n",
    "            cell = cv2.GaussianBlur(cell, (5,5), 0)\n",
    "            _, cell = cv2.threshold(cell, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "            \n",
    "            # Ensure digit is white on black background\n",
    "            if np.mean(cell[0:5, 0:5]) > 127:\n",
    "                cell = 255 - cell\n",
    "                \n",
    "            # Prepare input for model - match training data preprocessing\n",
    "            cell = cell.reshape(1, 28, 28, 1)\n",
    "            cell = cell.astype('float32') / 255.0\n",
    "            \n",
    "            # Get model prediction\n",
    "            prediction = model.predict(cell, verbose=0)\n",
    "            digit = np.argmax(prediction[0]) + 1  # Add 1 since model predicts 0-8 for digits 1-9\n",
    "            \n",
    "            # Only accept predictions with high confidence\n",
    "            if np.max(prediction[0]) > 0.3:\n",
    "                grid[i][j] = digit\n",
    "            else:\n",
    "                grid[i][j] = 0\n",
    "                \n",
    "    return grid\n",
    "\n",
    "def solve_puzzle(image, contour):\n",
    "    # First extract the grid\n",
    "    grid = extract_digits(image, contour)\n",
    "    print(grid)\n",
    "    \n",
    "    # Solve the Sudoku\n",
    "    if solve_sudoku(grid):\n",
    "        return grid\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Add the solving functions from previous response here\n",
    "def is_valid(board, num, pos):\n",
    "    # Check row\n",
    "    for x in range(len(board[0])):\n",
    "        if board[pos[0]][x] == num and pos[1] != x:\n",
    "            return False\n",
    "            \n",
    "    # Check column\n",
    "    for x in range(len(board)):\n",
    "        if board[x][pos[1]] == num and pos[0] != x:\n",
    "            return False\n",
    "    \n",
    "    # Check 3x3 box\n",
    "    box_x = pos[1] // 3\n",
    "    box_y = pos[0] // 3\n",
    "    for i in range(box_y * 3, box_y * 3 + 3):\n",
    "        for j in range(box_x * 3, box_x * 3 + 3):\n",
    "            if board[i][j] == num and (i, j) != pos:\n",
    "                return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def find_empty(board):\n",
    "    for i in range(len(board)):\n",
    "        for j in range(len(board[0])):\n",
    "            if board[i][j] == 0:\n",
    "                return (i, j)\n",
    "    return None\n",
    "\n",
    "def solve_sudoku(board):\n",
    "    empty = find_empty(board)\n",
    "    if not empty:\n",
    "        return True\n",
    "    \n",
    "    row, col = empty\n",
    "    \n",
    "    for num in range(1, 10):\n",
    "        if is_valid(board, num, (row, col)):\n",
    "            board[row][col] = num\n",
    "            \n",
    "            if solve_sudoku(board):\n",
    "                return True\n",
    "            \n",
    "            board[row][col] = 0\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Solve both puzzles\n",
    "solution1 = solve_puzzle(puzzle1_processed, puzzle1_contour)\n",
    "solution2 = solve_puzzle(puzzle2_processed, puzzle2_contour)\n",
    "\n",
    "# Display results\n",
    "if solution1 is not None:\n",
    "    print(\"Solution for Puzzle 1:\")\n",
    "    print(np.array(solution1))\n",
    "else:\n",
    "    print(\"Could not solve Puzzle 1\")\n",
    "\n",
    "if solution2 is not None:\n",
    "    print(\"\\nSolution for Puzzle 2:\")\n",
    "    print(np.array(solution2))\n",
    "else:\n",
    "    print(\"Could not solve Puzzle 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
